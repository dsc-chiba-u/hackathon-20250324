#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
PDFãƒ•ã‚¡ã‚¤ãƒ«ç”¨ã®Azure AI Searchã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ä½œæˆã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆ - æœ€é©åŒ–ç‰ˆ
Blobã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã«æ ¼ç´ã•ã‚ŒãŸPDFãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ä½œæˆã—ã¾ã™
"""

import os
import argparse
import json
import requests
import time
import logging
from dotenv import load_dotenv

# .envãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ç’°å¢ƒå¤‰æ•°ã‚’èª­ã¿è¾¼ã‚€
load_dotenv()

# API ãƒãƒ¼ã‚¸ãƒ§ãƒ³
API_VERSION = "2024-11-01-Preview"
DEFAULT_PDF_INDEX_NAME = "pdf-docs-index"
DEFAULT_CONTAINER_NAME = "documents"

# ãƒ­ã‚¬ãƒ¼ã®è¨­å®š
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def get_search_headers():
    """æ¤œç´¢APIãƒªã‚¯ã‚¨ã‚¹ãƒˆç”¨ã®ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’å–å¾—"""
    api_key = os.environ["AZURE_SEARCH_ADMIN_KEY"]
    return {
        "Content-Type": "application/json",
        "api-key": api_key
    }

def create_arg_parser():
    """ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ã®ãƒ‘ãƒ¼ã‚µãƒ¼ã‚’ä½œæˆ"""
    parser = argparse.ArgumentParser(description="PDFãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ä½œæˆ")
    parser.add_argument("--index-name", default=DEFAULT_PDF_INDEX_NAME, help=f"ä½œæˆã™ã‚‹ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹åï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: {DEFAULT_PDF_INDEX_NAME}ï¼‰")
    parser.add_argument("--container", default=DEFAULT_CONTAINER_NAME, help=f"æ¤œç´¢å¯¾è±¡ã®ã‚³ãƒ³ãƒ†ãƒŠåï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: {DEFAULT_CONTAINER_NAME}ï¼‰")
    parser.add_argument("--prefix", default="contents/pdf", help="Blobãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ï¼ˆPDFãƒ•ã‚¡ã‚¤ãƒ«ã®æ ¼ç´å ´æ‰€ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: contents/pdfï¼‰")
    parser.add_argument("--use-skillset", action="store_true", help="Cognitive Servicesã®ã‚¹ã‚­ãƒ«ã‚»ãƒƒãƒˆã‚’ä½¿ç”¨ã™ã‚‹")
    parser.add_argument("--delete-only", action="store_true", help="ãƒªã‚½ãƒ¼ã‚¹ã‚’å‰Šé™¤ã™ã‚‹ã ã‘")
    parser.add_argument("--debug", action="store_true", help="ãƒ‡ãƒãƒƒã‚°ãƒ­ã‚°ã‚’å‡ºåŠ›")
    parser.add_argument("--vector-search", action="store_true", help="ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ã‚’æœ‰åŠ¹ã«ã™ã‚‹")
    parser.add_argument("--env-file", default="environment/hackathon20250324.env", help="ç’°å¢ƒå¤‰æ•°ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: environment/hackathon20250324.envï¼‰")
    return parser

def delete_search_resources(endpoint, index_name):
    """æ¤œç´¢ãƒªã‚½ãƒ¼ã‚¹ï¼ˆã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã€ã‚¤ãƒ³ãƒ‡ã‚¯ã‚µãƒ¼ã€ã‚¹ã‚­ãƒ«ã‚»ãƒƒãƒˆã€ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ï¼‰ã‚’å‰Šé™¤"""
    headers = get_search_headers()

    # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’å‰Šé™¤
    try:
        response = requests.delete(
            f"{endpoint}/indexes/{index_name}?api-version={API_VERSION}",
            headers=headers
        )
        if response.status_code == 204 or response.status_code == 404:
            logger.info(f"ğŸ—‘ï¸  ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ '{index_name}' ã‚’å‰Šé™¤ã—ã¾ã—ãŸ")
        else:
            logger.warning(f"âš ï¸  ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ '{index_name}' ã®å‰Šé™¤ã«å¤±æ•—: {response.text}")
    except Exception as e:
        logger.error(f"âš ï¸ ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹å‰Šé™¤ã‚¨ãƒ©ãƒ¼: {str(e)}")

    # ã‚¤ãƒ³ãƒ‡ã‚¯ã‚µãƒ¼ã‚’å‰Šé™¤
    indexer_name = f"{index_name}-indexer"
    try:
        response = requests.delete(
            f"{endpoint}/indexers/{indexer_name}?api-version={API_VERSION}",
            headers=headers
        )
        if response.status_code == 204 or response.status_code == 404:
            logger.info(f"ğŸ—‘ï¸  ã‚¤ãƒ³ãƒ‡ã‚¯ã‚µãƒ¼ '{indexer_name}' ã‚’å‰Šé™¤ã—ã¾ã—ãŸ")
        else:
            logger.warning(f"âš ï¸  ã‚¤ãƒ³ãƒ‡ã‚¯ã‚µãƒ¼ '{indexer_name}' ã®å‰Šé™¤ã«å¤±æ•—: {response.text}")
    except Exception as e:
        logger.error(f"âš ï¸ ã‚¤ãƒ³ãƒ‡ã‚¯ã‚µãƒ¼å‰Šé™¤ã‚¨ãƒ©ãƒ¼: {str(e)}")

    # ã‚¹ã‚­ãƒ«ã‚»ãƒƒãƒˆã‚’å‰Šé™¤
    skillset_name = f"{index_name}-skillset"
    try:
        response = requests.delete(
            f"{endpoint}/skillsets/{skillset_name}?api-version={API_VERSION}",
            headers=headers
        )
        if response.status_code == 204 or response.status_code == 404:
            logger.info(f"ğŸ—‘ï¸  ã‚¹ã‚­ãƒ«ã‚»ãƒƒãƒˆ '{skillset_name}' ã‚’å‰Šé™¤ã—ã¾ã—ãŸ")
        else:
            logger.warning(f"âš ï¸  ã‚¹ã‚­ãƒ«ã‚»ãƒƒãƒˆ '{skillset_name}' ã®å‰Šé™¤ã«å¤±æ•—: {response.text}")
    except Exception as e:
        logger.error(f"âš ï¸ ã‚¹ã‚­ãƒ«ã‚»ãƒƒãƒˆå‰Šé™¤ã‚¨ãƒ©ãƒ¼: {str(e)}")

    # ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã‚’å‰Šé™¤
    datasource_name = f"{index_name}-datasource"
    try:
        response = requests.delete(
            f"{endpoint}/datasources/{datasource_name}?api-version={API_VERSION}",
            headers=headers
        )
        if response.status_code == 204 or response.status_code == 404:
            logger.info(f"ğŸ—‘ï¸  ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ '{datasource_name}' ã‚’å‰Šé™¤ã—ã¾ã—ãŸ")
        else:
            logger.warning(f"âš ï¸  ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ '{datasource_name}' ã®å‰Šé™¤ã«å¤±æ•—: {response.text}")
    except Exception as e:
        logger.error(f"âš ï¸ ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹å‰Šé™¤ã‚¨ãƒ©ãƒ¼: {str(e)}")

def create_pdf_index(endpoint, index_name, use_vector=False):
    """PDFãƒ•ã‚¡ã‚¤ãƒ«ç”¨ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ä½œæˆ"""
    headers = get_search_headers()

    # PDFãƒ•ã‚¡ã‚¤ãƒ«ç”¨ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹å®šç¾©
    index_definition = {
        "name": index_name,
        "fields": [
            {"name": "id", "type": "Edm.String", "key": True, "searchable": False},
            {"name": "content", "type": "Edm.String", "searchable": True, "filterable": False, "sortable": False, "facetable": False},
            {"name": "merged_content", "type": "Edm.String", "searchable": True, "filterable": False, "sortable": False, "facetable": False},
            {"name": "metadata_storage_name", "type": "Edm.String", "searchable": True, "filterable": True, "sortable": True},
            {"name": "metadata_storage_path", "type": "Edm.String", "searchable": False, "filterable": True, "sortable": True},
            {"name": "metadata_storage_size", "type": "Edm.Int64", "searchable": False, "filterable": True, "sortable": True},
            {"name": "metadata_content_type", "type": "Edm.String", "searchable": True, "filterable": True, "sortable": True},
            {"name": "language", "type": "Edm.String", "searchable": True, "filterable": True, "sortable": True},
            {"name": "translated_text", "type": "Edm.String", "searchable": True, "filterable": False, "sortable": False},
            {"name": "keyphrases", "type": "Collection(Edm.String)", "searchable": True, "filterable": True, "facetable": True},
            {"name": "translated_text_ja", "type": "Edm.String", "searchable": True, "filterable": False, "sortable": False},
            {"name": "translated_text_en", "type": "Edm.String", "searchable": True, "filterable": False, "sortable": False},
            {"name": "translated_text_fr", "type": "Edm.String", "searchable": True, "filterable": False, "sortable": False},
            {"name": "translated_text_es", "type": "Edm.String", "searchable": True, "filterable": False, "sortable": False},
            {"name": "translated_text_de", "type": "Edm.String", "searchable": True, "filterable": False, "sortable": False},
            {"name": "translated_text_zh_Hans", "type": "Edm.String", "searchable": True, "filterable": False, "sortable": False},
        ]
    }

    # ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’è¿½åŠ 
    if use_vector:
        vector_field = {
            "name": "vector",
            "type": "Collection(Edm.Single)",
            "searchable": True,
            "filterable": False,
            "sortable": False,
            "facetable": False,
            "dimensions": 1536,  # OpenAI ã®åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«ã®æ¬¡å…ƒæ•°
            "vectorSearchProfile": "my-vector-config"
        }
        index_definition["fields"].append(vector_field)
        
        # ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è¿½åŠ  (2024-11-01-Preview APIå‘ã‘ã«ä¿®æ­£)
        index_definition["vectorSearch"] = {
            "profiles": [
                {
                    "name": "my-vector-config",
                    "algorithm": "hnsw"  # algorithmConfiguration ã‹ã‚‰ algorithm ã«å¤‰æ›´
                }
            ],
            "algorithms": [
                {
                    "name": "hnsw",
                    "kind": "hnsw"
                }
            ]
        }

    # ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯æ¤œç´¢è¨­å®šã‚’è¿½åŠ 
    # æ³¨ï¼šç¾åœ¨ã®APIãƒãƒ¼ã‚¸ãƒ§ãƒ³ã§ã®äº’æ›æ€§ã®å•é¡Œã®ãŸã‚ã€ä¸€æ™‚çš„ã«ç„¡åŠ¹åŒ–
    # semantic_config_name = os.environ.get("AZURE_SEARCH_SEMANTIC_CONFIG", "")
    # if semantic_config_name:
    #     # è¨€èªã‚’æ—¥æœ¬èªã«è¨­å®š
    #     index_definition["semantic"] = {
    #         "configurations": [
    #             {
    #                 "name": semantic_config_name,
    #                 "prioritizedFields": {
    #                     "titleField": "metadata_storage_name",
    #                     "prioritizedContentFields": ["content"],
    #                     "prioritizedKeywordsFields": ["keyphrases"]
    #                 }
    #             }
    #         ]
    #     }

    # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ä½œæˆ
    try:
        response = requests.put(
            f"{endpoint}/indexes/{index_name}?api-version={API_VERSION}",
            headers=headers,
            json=index_definition
        )
        if response.status_code == 201 or response.status_code == 200:
            logger.info(f"âœ… ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ '{index_name}' ã‚’ä½œæˆã—ã¾ã—ãŸ")
            return True
        else:
            logger.error(f"âš ï¸  ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ '{index_name}' ã®ä½œæˆã«å¤±æ•—: {response.text}")
            return False
    except Exception as e:
        logger.error(f"âš ï¸ ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆã‚¨ãƒ©ãƒ¼: {str(e)}")
        return False

def create_skillset(endpoint, index_name, cognitive_services_key, cognitive_services_endpoint):
    """PDFå‡¦ç†ç”¨ã®ã‚¹ã‚­ãƒ«ã‚»ãƒƒãƒˆã‚’ä½œæˆ"""
    headers = get_search_headers()

    skillset_name = f"{index_name}-skillset"

    # PDFå‡¦ç†ç”¨ã®ã‚¹ã‚­ãƒ«ã‚»ãƒƒãƒˆå®šç¾©
    skillset_definition = {
        "name": skillset_name,
        "description": "PDF document processing skillset",
        "skills": [
            # PDFã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡ºã™ã‚‹ã‚¹ã‚­ãƒ«
            {
                "@odata.type": "#Microsoft.Skills.Text.SplitSkill",
                "textSplitMode": "pages",
                "maximumPageLength": 5000,
                "defaultLanguageCode": "ja",
                "context": "/document",
                "inputs": [
                    {
                        "name": "text",
                        "source": "/document/content"
                    }
                ],
                "outputs": [
                    {
                        "name": "textItems",
                        "targetName": "pages"
                    }
                ]
            },
            # ãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒãƒ¼ã‚¸ã™ã‚‹ã‚¹ã‚­ãƒ«
            {
                "@odata.type": "#Microsoft.Skills.Text.MergeSkill",
                "insertPreTag": " ",
                "insertPostTag": " ",
                "context": "/document",
                "inputs": [
                    {
                        "name": "text",
                        "source": "/document/content"
                    },
                    {
                        "name": "itemsToInsert",
                        "source": "/document/pages/*"
                    }
                ],
                "outputs": [
                    {
                        "name": "mergedText",
                        "targetName": "merged_content"
                    }
                ]
            },
            # è¨€èªæ¤œå‡ºã‚¹ã‚­ãƒ«
            {
                "@odata.type": "#Microsoft.Skills.Text.LanguageDetectionSkill",
                "context": "/document",
                "inputs": [
                    {
                        "name": "text",
                        "source": "/document/merged_content"
                    }
                ],
                "outputs": [
                    {
                        "name": "languageCode",
                        "targetName": "language"
                    }
                ]
            },
            # ã‚­ãƒ¼ãƒ•ãƒ¬ãƒ¼ã‚ºæŠ½å‡ºã‚¹ã‚­ãƒ«
            {
                "@odata.type": "#Microsoft.Skills.Text.KeyPhraseExtractionSkill",
                "context": "/document",
                "defaultLanguageCode": "ja",
                "inputs": [
                    {
                        "name": "text",
                        "source": "/document/merged_content"
                    },
                    {
                        "name": "languageCode",
                        "source": "/document/language"
                    }
                ],
                "outputs": [
                    {
                        "name": "keyPhrases",
                        "targetName": "keyphrases"
                    }
                ]
            },
            # æ—¥æœ¬èªã‹ã‚‰è‹±èªã¸ã®ç¿»è¨³ã‚¹ã‚­ãƒ«
            {
                "@odata.type": "#Microsoft.Skills.Text.TranslationSkill",
                "context": "/document",
                "defaultToLanguageCode": "en",
                "inputs": [
                    {
                        "name": "text",
                        "source": "/document/merged_content"
                    }
                ],
                "outputs": [
                    {
                        "name": "translatedText",
                        "targetName": "translated_text_en"
                    }
                ]
            },
            # è‹±èªã‹ã‚‰æ—¥æœ¬èªã¸ã®ç¿»è¨³ã‚¹ã‚­ãƒ«
            {
                "@odata.type": "#Microsoft.Skills.Text.TranslationSkill",
                "context": "/document",
                "defaultFromLanguageCode": "en",
                "defaultToLanguageCode": "ja",
                "inputs": [
                    {
                        "name": "text",
                        "source": "/document/merged_content"
                    }
                ],
                "outputs": [
                    {
                        "name": "translatedText",
                        "targetName": "translated_text_ja"
                    }
                ]
            },
            # è‹±èªã‹ã‚‰ãƒ•ãƒ©ãƒ³ã‚¹èªã¸ã®ç¿»è¨³ã‚¹ã‚­ãƒ«
            {
                "@odata.type": "#Microsoft.Skills.Text.TranslationSkill",
                "context": "/document",
                "defaultFromLanguageCode": "en",
                "defaultToLanguageCode": "fr",
                "inputs": [
                    {
                        "name": "text",
                        "source": "/document/merged_content"
                    }
                ],
                "outputs": [
                    {
                        "name": "translatedText",
                        "targetName": "translated_text_fr"
                    }
                ]
            },
            # è‹±èªã‹ã‚‰ã‚¹ãƒšã‚¤ãƒ³èªã¸ã®ç¿»è¨³ã‚¹ã‚­ãƒ«
            {
                "@odata.type": "#Microsoft.Skills.Text.TranslationSkill",
                "context": "/document",
                "defaultFromLanguageCode": "en",
                "defaultToLanguageCode": "es",
                "inputs": [
                    {
                        "name": "text",
                        "source": "/document/merged_content"
                    }
                ],
                "outputs": [
                    {
                        "name": "translatedText",
                        "targetName": "translated_text_es"
                    }
                ]
            },
            # è‹±èªã‹ã‚‰ãƒ‰ã‚¤ãƒ„èªã¸ã®ç¿»è¨³ã‚¹ã‚­ãƒ«
            {
                "@odata.type": "#Microsoft.Skills.Text.TranslationSkill",
                "context": "/document",
                "defaultFromLanguageCode": "en",
                "defaultToLanguageCode": "de",
                "inputs": [
                    {
                        "name": "text",
                        "source": "/document/merged_content"
                    }
                ],
                "outputs": [
                    {
                        "name": "translatedText",
                        "targetName": "translated_text_de"
                    }
                ]
            },
            # è‹±èªã‹ã‚‰ä¸­å›½èªç°¡ä½“å­—ã¸ã®ç¿»è¨³ã‚¹ã‚­ãƒ«
            {
                "@odata.type": "#Microsoft.Skills.Text.TranslationSkill",
                "context": "/document",
                "defaultFromLanguageCode": "en",
                "defaultToLanguageCode": "zh-Hans",
                "inputs": [
                    {
                        "name": "text",
                        "source": "/document/merged_content"
                    }
                ],
                "outputs": [
                    {
                        "name": "translatedText",
                        "targetName": "translated_text_zh_Hans"
                    }
                ]
            }
        ],
        "cognitiveServices": {
            "@odata.type": "#Microsoft.Azure.Search.CognitiveServicesByKey",
            "description": "Cognitive Services",
            "key": cognitive_services_key
        }
    }

    # ãƒ™ã‚¯ãƒˆãƒ«åŸ‹ã‚è¾¼ã¿ã‚’ç”Ÿæˆã™ã‚‹ã‚«ã‚¹ã‚¿ãƒ ã‚¹ã‚­ãƒ«
    # æ³¨ï¼šç¾åœ¨ã®APIãƒãƒ¼ã‚¸ãƒ§ãƒ³ã§ã®äº’æ›æ€§ã®å•é¡Œã®ãŸã‚ã€ä¸€æ™‚çš„ã«ç„¡åŠ¹åŒ–
    # openai_endpoint = os.environ.get("AZURE_OPENAI_ENDPOINT", "")
    # openai_api_key = os.environ.get("AZURE_OPENAI_API_KEY", "")
    # embedding_deployment = os.environ.get("AZURE_OPENAI_EMBEDDING_DEPLOYMENT", "")
    
    # if openai_endpoint and openai_api_key and embedding_deployment:
    #     # ãƒ™ã‚¯ãƒˆãƒ«åŸ‹ã‚è¾¼ã¿ç”¨ã®ã‚«ã‚¹ã‚¿ãƒ Webã‚¹ã‚­ãƒ«
    #     vector_skill = {
    #         "@odata.type": "#Microsoft.Skills.Custom.WebApiSkill",
    #         "name": "text-embedding-skill",
    #         "description": "Generate vector embeddings for text using Azure OpenAI",
    #         "uri": "https://aoai-vector-skill.azurewebsites.net/api/vectorize",
    #         "httpMethod": "POST",
    #         "timeout": "PT2M",
    #         "context": "/document",
    #         "batchSize": 1,
    #         "inputs": [
    #             {
    #                 "name": "text",
    #                 "source": "/document/merged_content"
    #             },
    #             {
    #                 "name": "openai_endpoint",
    #                 "source": "_openai_endpoint"
    #             },
    #             {
    #                 "name": "openai_api_key",
    #                 "source": "_openai_api_key"
    #             },
    #             {
    #                 "name": "openai_deployment",
    #                 "source": "_openai_deployment"
    #             }
    #         ],
    #         "outputs": [
    #             {
    #                 "name": "vector",
    #                 "targetName": "vector"
    #             }
    #         ],
    #         "httpHeaders": {}
    #     }
        
    #     # ã‚¹ã‚­ãƒ«ã‚»ãƒƒãƒˆã«ãƒ™ã‚¯ãƒˆãƒ«åŸ‹ã‚è¾¼ã¿ã‚¹ã‚­ãƒ«ã‚’è¿½åŠ 
    #     skillset_definition["skills"].append(vector_skill)
        
    #     # ç’°å¢ƒå¤‰æ•°ã‚’è¨­å®š - æœ€æ–°ã®APIã§ã¯inlineãƒ—ãƒ­ãƒ‘ãƒ†ã‚£ãŒä½¿ç”¨ã§ããªã„
    #     # inline ã®ä»£ã‚ã‚Šã« parameters ã‚’ä½¿ç”¨
    #     skillset_definition["knowledgeStore"] = {
    #         "projections": []
    #     }
    #     skillset_definition["parameters"] = {
    #         "_openai_endpoint": openai_endpoint,
    #         "_openai_api_key": openai_api_key,
    #         "_openai_deployment": embedding_deployment
    #     }

    # ã‚¹ã‚­ãƒ«ã‚»ãƒƒãƒˆã‚’ä½œæˆ
    try:
        response = requests.put(
            f"{endpoint}/skillsets/{skillset_name}?api-version={API_VERSION}",
            headers=headers,
            json=skillset_definition
        )
        if response.status_code == 201 or response.status_code == 200:
            logger.info(f"âœ… ã‚¹ã‚­ãƒ«ã‚»ãƒƒãƒˆ '{skillset_name}' ã‚’ä½œæˆã—ã¾ã—ãŸ")
            return True
        else:
            logger.error(f"âš ï¸  ã‚¹ã‚­ãƒ«ã‚»ãƒƒãƒˆ '{skillset_name}' ã®ä½œæˆã«å¤±æ•—: {response.text}")
            return False
    except Exception as e:
        logger.error(f"âš ï¸ ã‚¹ã‚­ãƒ«ã‚»ãƒƒãƒˆä½œæˆã‚¨ãƒ©ãƒ¼: {str(e)}")
        return False

def create_datasource(endpoint, index_name, container_name, connection_string, prefix):
    """Blobãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã‚’ä½œæˆ"""
    headers = get_search_headers()

    datasource_name = f"{index_name}-datasource"

    # ç‰¹å®šã®ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ã®PDFãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿ã‚’å¯¾è±¡ã¨ã™ã‚‹
    query = prefix  # f"{prefix}/*.pdf" ã‹ã‚‰å¤‰æ›´

    # ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹å®šç¾©
    datasource_definition = {
        "name": datasource_name,
        "description": "PDF documents in Azure Blob Storage",
        "type": "azureblob",
        "credentials": {
            "connectionString": connection_string
        },
        "container": {
            "name": container_name,
            "query": query
        },
        "dataDeletionDetectionPolicy": {
            "@odata.type": "#Microsoft.Azure.Search.SoftDeleteColumnDeletionDetectionPolicy",
            "softDeleteColumnName": "isDeleted",
            "softDeleteMarkerValue": "true"
        }
    }

    # ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã‚’ä½œæˆ
    try:
        response = requests.put(
            f"{endpoint}/datasources/{datasource_name}?api-version={API_VERSION}",
            headers=headers,
            json=datasource_definition
        )
        if response.status_code == 201 or response.status_code == 200:
            logger.info(f"âœ… ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ '{datasource_name}' ã‚’ä½œæˆã—ã¾ã—ãŸ")
            return True
        else:
            logger.error(f"âš ï¸  ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ '{datasource_name}' ã®ä½œæˆã«å¤±æ•—: {response.text}")
            return False
    except Exception as e:
        logger.error(f"âš ï¸ ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ä½œæˆã‚¨ãƒ©ãƒ¼: {str(e)}")
        return False

def create_indexer(endpoint, index_name, use_skillset):
    """PDFã‚¤ãƒ³ãƒ‡ã‚¯ã‚µãƒ¼ã‚’ä½œæˆ"""
    headers = get_search_headers()

    indexer_name = f"{index_name}-indexer"
    datasource_name = f"{index_name}-datasource"
    skillset_name = f"{index_name}-skillset"

    # ã‚¤ãƒ³ãƒ‡ã‚¯ã‚µãƒ¼å®šç¾©
    indexer_definition = {
        "name": indexer_name,
        "description": "PDF document indexer",
        "dataSourceName": datasource_name,
        "targetIndexName": index_name,
        "parameters": {
            "configuration": {
                "dataToExtract": "contentAndMetadata",
                "parsingMode": "default",
                "indexStorageMetadataOnlyForOversizedDocuments": True,
                "indexedFileNameExtensions": ".pdf",
                "failOnUnsupportedContentType": False,
                "failOnUnprocessableDocument": False
            }
        },
        "fieldMappings": [
            {
                "sourceFieldName": "metadata_storage_path",
                "targetFieldName": "id",
                "mappingFunction": {
                    "name": "base64Encode"
                }
            },
            {
                "sourceFieldName": "metadata_storage_path",
                "targetFieldName": "metadata_storage_path"
            },
            {
                "sourceFieldName": "metadata_storage_name",
                "targetFieldName": "metadata_storage_name"
            },
            {
                "sourceFieldName": "metadata_storage_size",
                "targetFieldName": "metadata_storage_size"
            },
            {
                "sourceFieldName": "metadata_content_type",
                "targetFieldName": "metadata_content_type"
            }
        ],
        "outputFieldMappings": []
    }

    # ã‚¹ã‚­ãƒ«ã‚»ãƒƒãƒˆãŒæœ‰åŠ¹ãªå ´åˆã¯ãƒãƒƒãƒ”ãƒ³ã‚°ã‚’è¿½åŠ 
    if use_skillset:
        indexer_definition["skillsetName"] = skillset_name
        indexer_definition["outputFieldMappings"] = [
            {
                "sourceFieldName": "/document/language",
                "targetFieldName": "language"
            },
            {
                "sourceFieldName": "/document/merged_content",
                "targetFieldName": "content"
            },
            {
                "sourceFieldName": "/document/merged_content",
                "targetFieldName": "merged_content"
            },
            {
                "sourceFieldName": "/document/keyphrases",
                "targetFieldName": "keyphrases"
            },
            {
                "sourceFieldName": "/document/translated_text_ja",
                "targetFieldName": "translated_text_ja"
            },
            {
                "sourceFieldName": "/document/translated_text_en",
                "targetFieldName": "translated_text_en"
            },
            {
                "sourceFieldName": "/document/translated_text_fr",
                "targetFieldName": "translated_text_fr"
            },
            {
                "sourceFieldName": "/document/translated_text_es",
                "targetFieldName": "translated_text_es"
            },
            {
                "sourceFieldName": "/document/translated_text_de",
                "targetFieldName": "translated_text_de"
            },
            {
                "sourceFieldName": "/document/translated_text_zh_Hans",
                "targetFieldName": "translated_text_zh_Hans"
            }
        ]
        
        # ãƒ™ã‚¯ãƒˆãƒ«åŸ‹ã‚è¾¼ã¿ãƒãƒƒãƒ”ãƒ³ã‚°ã‚‚è¿½åŠ ï¼ˆã‚¹ã‚­ãƒ«ã‚»ãƒƒãƒˆã«å«ã¾ã‚Œã¦ã„ã‚‹å ´åˆï¼‰
        # æ³¨ï¼šç¾åœ¨ã®APIãƒãƒ¼ã‚¸ãƒ§ãƒ³ã§ã®äº’æ›æ€§ã®å•é¡Œã®ãŸã‚ã€ä¸€æ™‚çš„ã«ç„¡åŠ¹åŒ–
        # vector_mapping = {
        #     "sourceFieldName": "/document/vector",
        #     "targetFieldName": "vector"
        # }
        # indexer_definition["outputFieldMappings"].append(vector_mapping)

    # ã‚¤ãƒ³ãƒ‡ã‚¯ã‚µãƒ¼ã‚’ä½œæˆ
    try:
        response = requests.put(
            f"{endpoint}/indexers/{indexer_name}?api-version={API_VERSION}",
            headers=headers,
            json=indexer_definition
        )
        if response.status_code == 201 or response.status_code == 200:
            logger.info(f"âœ… ã‚¤ãƒ³ãƒ‡ã‚¯ã‚µãƒ¼ '{indexer_name}' ã‚’ä½œæˆã—ã¾ã—ãŸ")
            return True
        else:
            logger.error(f"âš ï¸  ã‚¤ãƒ³ãƒ‡ã‚¯ã‚µãƒ¼ '{indexer_name}' ã®ä½œæˆã«å¤±æ•—: {response.text}")
            return False
    except Exception as e:
        logger.error(f"âš ï¸ ã‚¤ãƒ³ãƒ‡ã‚¯ã‚µãƒ¼ä½œæˆã‚¨ãƒ©ãƒ¼: {str(e)}")
        return False

def run_indexer(endpoint, index_name):
    """PDFã‚¤ãƒ³ãƒ‡ã‚¯ã‚µãƒ¼ã‚’å®Ÿè¡Œ"""
    headers = get_search_headers()
    indexer_name = f"{index_name}-indexer"

    try:
        response = requests.post(
            f"{endpoint}/indexers/{indexer_name}/run?api-version={API_VERSION}",
            headers=headers
        )
        if response.status_code == 202:
            logger.info(f"âœ… ã‚¤ãƒ³ãƒ‡ã‚¯ã‚µãƒ¼ '{indexer_name}' ã‚’å®Ÿè¡Œã—ã¾ã—ãŸ")
            return True
        else:
            logger.error(f"âš ï¸  ã‚¤ãƒ³ãƒ‡ã‚¯ã‚µãƒ¼ '{indexer_name}' ã®å®Ÿè¡Œã«å¤±æ•—: {response.text}")
            return False
    except Exception as e:
        logger.error(f"âš ï¸ ã‚¤ãƒ³ãƒ‡ã‚¯ã‚µãƒ¼å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {str(e)}")
        return False

def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    # ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ã®è§£æ
    parser = create_arg_parser()
    args = parser.parse_args()

    # ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰ãŒæœ‰åŠ¹ãªå ´åˆã¯ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«ã‚’DEBUGã«è¨­å®š
    if args.debug:
        logger.setLevel(logging.DEBUG)
        logger.debug("ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰ãŒæœ‰åŠ¹ã§ã™")

    # ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ã§æŒ‡å®šã•ã‚ŒãŸç’°å¢ƒå¤‰æ•°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€
    if args.env_file:
        logger.info(f"ç’°å¢ƒå¤‰æ•°ãƒ•ã‚¡ã‚¤ãƒ« '{args.env_file}' ã‚’èª­ã¿è¾¼ã¿ã¾ã™")
        load_dotenv(args.env_file)

    # Azure AI Search ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã‚’å–å¾—
    search_endpoint = os.environ.get("AZURE_SEARCH_ENDPOINT")
    if not search_endpoint:
        logger.error("âš ï¸ ç’°å¢ƒå¤‰æ•° 'AZURE_SEARCH_ENDPOINT' ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        return False

    # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹åã‚’å–å¾—
    index_name = args.index_name

    # æ—¢å­˜ã®ãƒªã‚½ãƒ¼ã‚¹ã‚’å‰Šé™¤
    delete_search_resources(search_endpoint, index_name)

    # å‰Šé™¤ã®ã¿ã®ãƒ¢ãƒ¼ãƒ‰ã®å ´åˆã¯ã“ã“ã§çµ‚äº†
    if args.delete_only:
        logger.info("âœ… ãƒªã‚½ãƒ¼ã‚¹ã®å‰Šé™¤ãŒå®Œäº†ã—ã¾ã—ãŸ")
        return True

    # PDFã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ä½œæˆ
    if not create_pdf_index(search_endpoint, index_name, args.vector_search):
        logger.error("âš ï¸ ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®ä½œæˆã«å¤±æ•—ã—ã¾ã—ãŸ")
        return False

    # ã‚¹ã‚­ãƒ«ã‚»ãƒƒãƒˆã‚’ä½¿ç”¨ã™ã‚‹å ´åˆ
    if args.use_skillset:
        # Cognitive Services ã®æ¥ç¶šæƒ…å ±ã‚’å–å¾—
        # AIServices.S0ã‚¿ã‚¤ãƒ—ã§ã¯ãªãã€all-in-oneã‚¿ã‚¤ãƒ—ã®ã‚­ãƒ¼ãŒå¿…è¦
        cognitive_services_key = os.environ.get("AZURE_COGNITIVE_ALLINONE_KEY")
        cognitive_services_endpoint = os.environ.get("AZURE_COGNITIVE_ALLINONE_ENDPOINT")

        if not cognitive_services_key or not cognitive_services_endpoint:
            logger.error("âš ï¸ Cognitive Services ã®æ¥ç¶šæƒ…å ±ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
            return False

        # ã‚¹ã‚­ãƒ«ã‚»ãƒƒãƒˆã‚’ä½œæˆ
        if not create_skillset(search_endpoint, index_name, cognitive_services_key, cognitive_services_endpoint):
            logger.error("âš ï¸ ã‚¹ã‚­ãƒ«ã‚»ãƒƒãƒˆã®ä½œæˆã«å¤±æ•—ã—ã¾ã—ãŸ")
            return False

    # Blobã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã®æ¥ç¶šæƒ…å ±ã‚’å–å¾—
    storage_connection_string = os.environ.get("AZURE_STORAGE_CONNECTION_STRING")
    if not storage_connection_string:
        logger.error("âš ï¸ ç’°å¢ƒå¤‰æ•° 'AZURE_STORAGE_CONNECTION_STRING' ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        return False

    # ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã‚’ä½œæˆ
    if not create_datasource(search_endpoint, index_name, args.container, storage_connection_string, args.prefix):
        logger.error("âš ï¸ ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã®ä½œæˆã«å¤±æ•—ã—ã¾ã—ãŸ")
        return False

    # ã‚¤ãƒ³ãƒ‡ã‚¯ã‚µãƒ¼ã‚’ä½œæˆ
    if not create_indexer(search_endpoint, index_name, args.use_skillset):
        logger.error("âš ï¸ ã‚¤ãƒ³ãƒ‡ã‚¯ã‚µãƒ¼ã®ä½œæˆã«å¤±æ•—ã—ã¾ã—ãŸ")
        return False

    # ã‚¤ãƒ³ãƒ‡ã‚¯ã‚µãƒ¼ã‚’å®Ÿè¡Œ
    if not run_indexer(search_endpoint, index_name):
        logger.error("âš ï¸ ã‚¤ãƒ³ãƒ‡ã‚¯ã‚µãƒ¼ã®å®Ÿè¡Œã«å¤±æ•—ã—ã¾ã—ãŸ")
        return False

    logger.info(f"âœ… ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ '{index_name}' ã®ä½œæˆãŒå®Œäº†ã—ã¾ã—ãŸ")
    logger.info("ğŸ” ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®ä½œæˆçŠ¶æ³ã¯ Azure Portal ã§ç¢ºèªã§ãã¾ã™")
    return True

if __name__ == "__main__":
    main() 